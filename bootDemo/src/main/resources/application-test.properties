# Server settings (ServerProperties)
#端口
server.port=8091
server.address=127.0.0.1
#server.sessionTimeout=30
#访问路径名称
server.servlet.context-path=/boot
com.blog.title=Spring Boot Course
# 数据库访问配置
# 主数据源，默认的
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://192.168.1.101:3306/sport?useSSL=false&useUnicode=true&characterEncoding=utf8&autoReconnect=true&failOverReadOnly=false&allowMultiQueries=true&zeroDateTimeBehavior=convertToNull
spring.datasource.username=root
spring.datasource.password=123qwe
#spring.data.mongodb.host=49.234.238.59
#spring.data.mongodb.port=27017
#spring.data.mongodb.database=sportMog
# Mybatis配置
mybatis.mapperLocations=classpath:mapper/*.xml
mybatis.configLocation=classpath:config/mybatis.xml
# 下面为连接池的补充设置，应用到上面所有数据源中
# 初始化大小，最小，最大
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROMDUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.poolPreparedStatements=true
spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
# 合并多个DruidDataSource的监控数据
#spring.datasource.useGlobalDataSourceStat=true
#ES配置
#spring.data.elasticsearch.clustername=my-es7
#elasticSearch.host=172.20.4.23
#elasticSearch.port=9200
#elasticSearch.client.connectNum=10
#elasticSearch.client.connectPerRoute=50
## kafka
## kafka服务器地址(可以多个)
#spring.kafka.bootstrap-servers=172.20.4.24:9092,172.20.4.23:9092,172.22.31.47:9092
## 指定一个默认的组名
#spring.kafka.consumer.group-id=kafka2
## earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
## latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
## none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
#spring.kafka.consumer.auto-offset-reset=earliest
## key/value的反序列化
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
## key/value的序列化
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
## 批量抓取
#spring.kafka.producer.batch-size=65536
## 缓存容量
#spring.kafka.producer.buffer-memory=524288
## 服务器地址
#spring.kafka.producer.bootstrap-servers=172.20.4.24:9092,172.20.4.23:9092,172.22.31.47:9092
#scheduled.first.time=
wxchat.appid=wxa4bb858ebd7f1728
wxchat.appSecret=d7c5012dfda07f40bac6b79b417a2ae2
wxchat.url=https://api.weixin.qq.com/sns/jscode2session
# yml配置的优先级高于java配置；如果yml配置和java配置同时存在，则yml配置会覆盖java配置
#连接池的最大连接数，0代表不限；如果取0，需要考虑连接泄露导致系统崩溃的后果
spring.pool.maxTotalConnect=3500
#每个路由的最大连接数,如果只调用一个地址,可以将其设置为最大连接数
spring.pool.maxConnectPerRoute=3500
# 指客户端和服务器建立连接的超时时间,ms , 最大约21秒,因为内部tcp在进行三次握手建立连接时,默认tcp超时时间是20秒
spring.pool.connectTimeout=5000
# 指客户端从服务器读取数据包的间隔超时时间,不是总读取时间,也就是socket timeout,ms
spring.pool.readTimeout=120000
# 从连接池获取连接的timeout,不宜过大,ms
spring.pool.connectionRequestTimout=1000
# 重试次数
spring.pool.retryTimes=3
spring.pool.charset=UTF-8
# 长连接保持时间 单位s,不宜过长
spring.pool.keepAliveTime=10
# 针对不同的网址,长连接保持的存活时间,单位s,如果是频繁而持续的请求,可以设置小一点,不建议设置过大,避免大量无用连接占用内存资源
#spring.pool.keepAliveTargetHost.www.baidu.com: 5


